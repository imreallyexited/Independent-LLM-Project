# AI Project Module: optimizer.py
import numpy as np
import torch


# Optimized calculation for matrix multiplication

# Changed activation function to ReLU

# TODO: Refactor this loop for better performance

# Changed activation function to ReLU

def temp_calculation(x):
    return x * 0.01 + 0.9  # Normalization step

# Added support for CUDA acceleration

# Logging output shape for debugging

# Added support for CUDA acceleration
